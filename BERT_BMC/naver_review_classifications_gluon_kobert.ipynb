{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "GvjqOdDgT5zb",
    "outputId": "00449e1c-749d-414b-af20-d8adddadc251"
   },
   "outputs": [],
   "source": [
    "!pip install mxnet-cu101mkl\n",
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "-sx87sgK7_pz",
    "outputId": "9f1c67bf-7c67-45d7-88b7-4bbc7384a29b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\r\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-4f2iwiz1\r\n",
      "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-4f2iwiz1\r\n",
      "\u001b[31m  ERROR: Error [Errno 2] No such file or directory: 'git' while executing command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-4f2iwiz1\u001b[0m\r\n",
      "\u001b[31mERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mTNl7BKT2Fx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mxnet.gluon import nn, rnn\n",
    "from mxnet import gluon, autograd\n",
    "import gluonnlp as nlp\n",
    "from mxnet import nd \n",
    "import mxnet as mx\n",
    "import time\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from kobert.mxnet_kobert import get_mxnet_kobert_model\n",
    "from kobert.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cc-zco-ST2F_"
   },
   "source": [
    "### Loading KoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sudo -H pip install mxnet --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89lsydguT2GG"
   },
   "outputs": [],
   "source": [
    "# gpu 활성화 방법 ???\n",
    "# ctx = mx.gpu()\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "wI841Zb38XOn",
    "outputId": "f9794e99-c913-4ca0-b8fd-6e15ce9d74c7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# 모델 로딩\n",
    "bert_base, vocab = get_mxnet_kobert_model(use_decoder=False, use_classifier=False, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "NijpWe8J8isZ",
    "outputId": "d03d1cc1-327f-4b44-ed66-f02126687688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "id": "i69AUj9gT2Gk",
    "outputId": "050d42de-ac07-4c04-9f14-b5ea411df008",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([   2, 1370, 2362, 5330, 3322,    3, 1316, 6607, 7028,    3],\n",
       "        dtype=int32),\n",
       "  array(10, dtype=int32),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1], dtype=int32))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Dataset wrapper for lists and arrays.\n",
    "ds = gluon.data.SimpleDataset([['나 보기가 역겨워', '김소월']])\n",
    "\n",
    "\n",
    "\"\"\"버트는 입력 문장에 대해서 아래와 같은 작업을 요구\n",
    " 1. 각 토큰의 Vocabulary 인덱스를 추출해 이를 정해진 길이의 벡터로 생성.\n",
    " 2. 두 문장 혹은 하나의 문장이 들어올 수 있기 때문에 이들을 구분하기 위한 토큰 타입 벡터 생성\n",
    " 3. 유효 길이 벡터\n",
    "BERTSentenceTransform 은 위 작업을 편하게 진행해주는 함수\"\"\"\n",
    "# 출처: http://freesearch.pe.kr/archives/4963\n",
    "trans = nlp.data.BERTSentenceTransform(tok, max_seq_length=10)\n",
    "\n",
    "list(ds.transform(trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "4qy9g_UMVtdj",
    "outputId": "c4546df4-ce5b-4484-e245-309c90fed014",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-24 12:03:29--  https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.84.18, 2620:100:6034:18::a27d:5412\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.84.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/374ftkec978br3d/ratings_train.txt [following]\n",
      "--2021-08-24 12:03:30--  https://www.dropbox.com/s/dl/374ftkec978br3d/ratings_train.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc929c8f306b23331d335bbac2c5.dl.dropboxusercontent.com/cd/0/get/BU2GI8c-X5xgTfFu-aThzw1jCZqwSCP5F_FHs8uSt0KQeVh68Z0CJ-cLqAMqBDSH6Z-WusBBEcD1tmwSmihCvFWss1INzHG36npXZLj86bif3lX08uNzTISSA5l2Cg5i3UmpsRFND79ocmwQplHRyZZ_/file?dl=1# [following]\n",
      "--2021-08-24 12:03:30--  https://uc929c8f306b23331d335bbac2c5.dl.dropboxusercontent.com/cd/0/get/BU2GI8c-X5xgTfFu-aThzw1jCZqwSCP5F_FHs8uSt0KQeVh68Z0CJ-cLqAMqBDSH6Z-WusBBEcD1tmwSmihCvFWss1INzHG36npXZLj86bif3lX08uNzTISSA5l2Cg5i3UmpsRFND79ocmwQplHRyZZ_/file?dl=1\n",
      "Resolving uc929c8f306b23331d335bbac2c5.dl.dropboxusercontent.com (uc929c8f306b23331d335bbac2c5.dl.dropboxusercontent.com)... 162.125.84.15, 2620:100:6034:15::a27d:540f\n",
      "Connecting to uc929c8f306b23331d335bbac2c5.dl.dropboxusercontent.com (uc929c8f306b23331d335bbac2c5.dl.dropboxusercontent.com)|162.125.84.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [application/binary]\n",
      "Saving to: ‘ratings_train.txt?dl=1.1’\n",
      "\n",
      "ratings_train.txt?d 100%[===================>]  13.95M  4.99MB/s    in 2.8s    \n",
      "\n",
      "2021-08-24 12:03:34 (4.99 MB/s) - ‘ratings_train.txt?dl=1.1’ saved [14628807/14628807]\n",
      "\n",
      "--2021-08-24 12:03:34--  https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.84.18, 162.125.84.18, 2620:100:6034:18::a27d:5412\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.84.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/977gbwh542gdy94/ratings_test.txt [following]\n",
      "--2021-08-24 12:03:35--  https://www.dropbox.com/s/dl/977gbwh542gdy94/ratings_test.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc3630c8faf7160dd7368006a885.dl.dropboxusercontent.com/cd/0/get/BU0qlM5g3Y9lbzLlHnTqGa3qdoqj7pVQthNXZyBQlToT9v2oCjPQVdqf4sibvMdA9vNRqPbMQo9BnNhRk1EP0wW2cifAR4zHftkn7Cx5BmlmFaB6tyQ7L2FZ5eTFYwGBay52gTy6d_5ZV4nNHMVhKY3e/file?dl=1# [following]\n",
      "--2021-08-24 12:03:35--  https://uc3630c8faf7160dd7368006a885.dl.dropboxusercontent.com/cd/0/get/BU0qlM5g3Y9lbzLlHnTqGa3qdoqj7pVQthNXZyBQlToT9v2oCjPQVdqf4sibvMdA9vNRqPbMQo9BnNhRk1EP0wW2cifAR4zHftkn7Cx5BmlmFaB6tyQ7L2FZ5eTFYwGBay52gTy6d_5ZV4nNHMVhKY3e/file?dl=1\n",
      "Resolving uc3630c8faf7160dd7368006a885.dl.dropboxusercontent.com (uc3630c8faf7160dd7368006a885.dl.dropboxusercontent.com)... 162.125.84.15, 162.125.84.15, 2620:100:6034:15::a27d:540f, ...\n",
      "Connecting to uc3630c8faf7160dd7368006a885.dl.dropboxusercontent.com (uc3630c8faf7160dd7368006a885.dl.dropboxusercontent.com)|162.125.84.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [application/binary]\n",
      "Saving to: ‘ratings_test.txt?dl=1.1’\n",
      "\n",
      "ratings_test.txt?dl 100%[===================>]   4.67M  3.27MB/s    in 1.4s    \n",
      "\n",
      "2021-08-24 12:03:38 (3.27 MB/s) - ‘ratings_test.txt?dl=1.1’ saved [4893335/4893335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
    "!wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LfCTweqT2Gt"
   },
   "outputs": [],
   "source": [
    "\"\"\"Common tab separated text dataset that reads text fields based on provided sample splitter\n",
    "    and field separator.\n",
    "\n",
    "    The returned dataset includes samples, each of which can either be a list of text fields\n",
    "    if field_separator is specified, or otherwise a single string segment produced by the\n",
    "    sample_splitter.\"\"\"\n",
    "# 출처: https://nlp.gluon.ai/_modules/gluonnlp/data/dataset.html\n",
    "\n",
    "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pt0raV8uT2G2"
   },
   "outputs": [],
   "source": [
    "# 모든 학습 데이터는 배치단위로 입/출력이 정의되기 때문에 입력 데이터 처리와 \n",
    "# 레이블 처리를 동시에 배치 출력하기 위해 Dataset 클래스를 정의\n",
    "# 출처: http://freesearch.pe.kr/archives/4963\n",
    "\n",
    "class BERTDataset(mx.gluon.data.Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        sent_dataset = gluon.data.SimpleDataset([[\n",
    "            i[sent_idx],\n",
    "        ] for i in dataset])\n",
    "        self.sentences = sent_dataset.transform(transform)\n",
    "        self.labels = gluon.data.SimpleDataset(\n",
    "            [np.array(np.int32(i[label_idx])) for i in dataset])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtk-8pQST2G9"
   },
   "outputs": [],
   "source": [
    "max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_K_BLZP_T2HF"
   },
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhaw0H4ST2HM"
   },
   "outputs": [],
   "source": [
    "# 모든 버트 모델은 첫 클래스 레이블을 pooler 라고 네이밍 하고 있고 이 pooler 결과를 받아 \n",
    "# FC(fully connected) 레이어 하나를 추가해 간단하게 구성\n",
    "# 출처: http://freesearch.pe.kr/archives/4963\n",
    "\n",
    "class BERTClassifier(nn.Block):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 num_classes=2,\n",
    "                 dropout=None,\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(nn.Dense(units=num_classes))\n",
    "\n",
    "    def forward(self, inputs, token_types, valid_length=None):\n",
    "        _, pooler = self.bert(inputs, token_types, valid_length)\n",
    "        return self.classifier(pooler)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y00BOPwST2HX"
   },
   "outputs": [],
   "source": [
    " # 파라미터 설명\n",
    "# bert: BERTModel\n",
    "#    Bidirectional encoder with transformer.\n",
    "# num_classes : int, default is 2\n",
    "#    The number of target classes.\n",
    "# dropout : float or None, default 0.0.\n",
    "#    Dropout probability for the bert output.\n",
    "# 출처: https://nlp.gluon.ai/_modules/gluonnlp/model/bert.html\n",
    "model = BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "\n",
    "# 분류 레이어만 초기화 한다. \n",
    "# Create a initializer that initialize the weight with normal(0, sd)\n",
    "# 출처: https://mxnet.apache.org/versions/1.6/api/r/docs/api/mx.init.normal.html\n",
    "model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "model.hybridize()\n",
    "\n",
    "# softmax cross entropy loss for classification\n",
    "# SoftmaxCELoss(): Computes the softmax cross entropy loss\n",
    "loss_function = gluon.loss.SoftmaxCELoss()\n",
    "\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2dLhnHkT2Hf"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 5e-5\n",
    "\n",
    "# DataLoader - Loads data from a dataset and returns mini-batches of data.\n",
    "# num_workers (int, default 0) – The number of multiprocessing workers to use for data preprocessing.\n",
    "# 출처: http://34.201.8.176/versions/io/api/python/gluon/data.html#mxnet.gluon.data.DataLoader\n",
    "train_dataloader = mx.gluon.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=int(batch_size/2), num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESo76UH-T2Hr"
   },
   "outputs": [],
   "source": [
    "# mxnet.gluon.Trainer(params, optimizer, optimizer_params=None, kvstore='device', compression_params=None, update_on_kvstore=None)\n",
    "# params (ParameterDict) – The set of parameters to optimize.\n",
    "# optimizer (str or Optimizer) – The optimizer to use.\n",
    "# optimizer_params (dict) – Key-word arguments to be passed to optimizer constructor. For example, {‘learning_rate’: 0.1}. \n",
    "# All optimizers accept learning_rate, wd (weight decay), clip_gradient, and lr_scheduler. \n",
    "# See each optimizer’s constructor for a list of additional supported arguments.\n",
    "# 출처: http://34.201.8.176/versions/io/api/python/gluon/gluon.html?highlight=gluon.trainer#mxnet.gluon.Trainer\n",
    "trainer = gluon.Trainer(model.collect_params(), 'bertadam',\n",
    "                        {'learning_rate': lr, 'epsilon': 1e-9, 'wd':0.01})\n",
    "\n",
    "log_interval = 4\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wspMBDOAT2H0"
   },
   "outputs": [],
   "source": [
    "# LayerNorm과 Bias에는 Weight Decay를 적용하지 않는다. \n",
    "# ???\n",
    "for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n",
    "    v.wd_mult = 0.0\n",
    "params = [\n",
    "    p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCR6AMKHT2H6"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, data_iter, ctx=ctx):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    i = 0\n",
    "    for i, (t,v,s, label) in enumerate(data_iter):\n",
    "        token_ids = t.as_in_context(ctx)\n",
    "        valid_length = v.as_in_context(ctx)\n",
    "        segment_ids = s.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "        acc.update(preds=output, labels=label)\n",
    "        if i > 1000:\n",
    "            break\n",
    "        i += 1\n",
    "    return(acc.get()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkcW6GyeT2IA"
   },
   "outputs": [],
   "source": [
    "#learning rate warmup을 위한 준비 \n",
    "accumulate = 4\n",
    "step_size = batch_size * accumulate if accumulate else batch_size # 128\n",
    "num_train_examples = len(data_train) # 15만개\n",
    "num_train_steps = int(num_train_examples / step_size * num_epochs) #  5859 = 15만 / 128*5\n",
    "warmup_ratio = 0.1 # ???\n",
    "num_warmup_steps = int(num_train_steps * warmup_ratio) # 585 = 5859 *  0.1\n",
    "step_num = 0\n",
    "\n",
    "\n",
    "all_model_params = model.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yf_rpZTq6uES"
   },
   "outputs": [],
   "source": [
    "# Set grad_req if gradient accumulation is required\n",
    "if accumulate and accumulate > 1:\n",
    "    for p in params:\n",
    "        p.grad_req = 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "colab_type": "code",
    "id": "0mJ3Pw_VT2IH",
    "outputId": "abc9ecfb-8674-445f-cd5d-3fcd57252f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 50/4688] loss=9.1173, lr=0.0000010256, acc=0.516\n",
      "[Epoch 1 Batch 100/4688] loss=8.6865, lr=0.0000020513, acc=0.521\n",
      "[Epoch 1 Batch 150/4688] loss=8.4828, lr=0.0000031624, acc=0.538\n",
      "[Epoch 1 Batch 200/4688] loss=7.5561, lr=0.0000041880, acc=0.581\n",
      "[Epoch 1 Batch 250/4688] loss=7.1114, lr=0.0000052991, acc=0.609\n",
      "[Epoch 1 Batch 300/4688] loss=6.7686, lr=0.0000063248, acc=0.631\n",
      "[Epoch 1 Batch 350/4688] loss=5.6022, lr=0.0000074359, acc=0.656\n",
      "[Epoch 1 Batch 400/4688] loss=5.4755, lr=0.0000084615, acc=0.675\n",
      "[Epoch 1 Batch 450/4688] loss=5.3786, lr=0.0000095726, acc=0.688\n",
      "[Epoch 1 Batch 500/4688] loss=5.0646, lr=0.0000105983, acc=0.700\n",
      "[Epoch 1 Batch 550/4688] loss=4.7464, lr=0.0000117094, acc=0.712\n",
      "[Epoch 1 Batch 600/4688] loss=4.6596, lr=0.0000127350, acc=0.723\n",
      "[Epoch 1 Batch 650/4688] loss=4.4470, lr=0.0000138462, acc=0.732\n",
      "[Epoch 1 Batch 700/4688] loss=4.5672, lr=0.0000148718, acc=0.740\n",
      "[Epoch 1 Batch 750/4688] loss=4.6551, lr=0.0000159829, acc=0.746\n",
      "[Epoch 1 Batch 800/4688] loss=4.4216, lr=0.0000170085, acc=0.752\n",
      "[Epoch 1 Batch 850/4688] loss=4.2021, lr=0.0000181197, acc=0.759\n",
      "[Epoch 1 Batch 900/4688] loss=4.5788, lr=0.0000191453, acc=0.763\n",
      "[Epoch 1 Batch 950/4688] loss=4.4971, lr=0.0000202564, acc=0.768\n",
      "[Epoch 1 Batch 1000/4688] loss=4.5034, lr=0.0000212821, acc=0.771\n",
      "[Epoch 1 Batch 1050/4688] loss=3.9356, lr=0.0000223932, acc=0.776\n",
      "[Epoch 1 Batch 1100/4688] loss=4.3714, lr=0.0000234188, acc=0.779\n",
      "[Epoch 1 Batch 1150/4688] loss=3.8813, lr=0.0000245299, acc=0.783\n",
      "[Epoch 1 Batch 1200/4688] loss=4.3438, lr=0.0000255556, acc=0.786\n",
      "[Epoch 1 Batch 1250/4688] loss=4.2709, lr=0.0000266667, acc=0.789\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59421/4214708798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m               \u001b[0mall_model_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mstep_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \"\"\"\n\u001b[1;32m   2562\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m         check_call(_LIB.MXNDArraySyncCopyToCPU(\n\u001b[0m\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_id in range(num_epochs):\n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(train_dataloader):\n",
    "        if step_num < num_warmup_steps:\n",
    "            new_lr = lr * step_num / num_warmup_steps\n",
    "        else:\n",
    "            non_warmup_steps = step_num - num_warmup_steps\n",
    "            offset = non_warmup_steps / (num_train_steps - num_warmup_steps)\n",
    "            new_lr = lr - offset * lr\n",
    "        trainer.set_learning_rate(new_lr)\n",
    "        with mx.autograd.record():\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "        # backward computation\n",
    "        ls.backward()\n",
    "        if not accumulate or (batch_id + 1) % accumulate == 0:\n",
    "          trainer.allreduce_grads()\n",
    "          nlp.utils.clip_grad_global_norm(params, 1)\n",
    "          trainer.update(accumulate if accumulate else 1)\n",
    "          step_num += 1\n",
    "          if accumulate and accumulate > 1:\n",
    "              # set grad to zero for gradient accumulation\n",
    "              all_model_params.zero_grad()\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "        if (batch_id + 1) % (50) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.10f}, acc={:.3f}'\n",
    "                         .format(epoch_id + 1, batch_id + 1, len(train_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0\n",
    "    test_acc = evaluate_accuracy(model, test_dataloader, ctx)\n",
    "    print('Test Acc : {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "naver_review_classifications_gluon_bert.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
